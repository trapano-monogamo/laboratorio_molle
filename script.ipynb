{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spring's constant measuring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import os\n",
    "from functools import reduce\n",
    "\n",
    "from modules import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "The following code creates a table (dict) with entries that have:\n",
    "- as key, the name of the file from which the data is read\n",
    "- as value, the DataFrame returned by pandas when reading that file\n",
    "\n",
    "Getting data from this table involves using the file from which the data is read as key and then parsing the columns of the corresponding DataFrame.\n",
    "\n",
    "e.g.:\n",
    "\n",
    "```\n",
    "masses_measurements = datasets['misure_masse']\n",
    "used_objects = masses_measurements[masses_measurements.columns[0]]\n",
    "masses = masses_measurements[masses_measurements.columns[1]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect filenames of exported data\n",
    "\n",
    "data_dir = \"./data\"\n",
    "\n",
    "csv_data = []\n",
    "excel_data = []\n",
    "\n",
    "for root, dirs, files in os.walk(data_dir):\n",
    "    for file in files:\n",
    "        current_file_path = os.path.join(root, file).replace(\n",
    "            \"\\\\\", \"/\"\n",
    "        )  # fix the unbearably frustrating flaws of the wanna-be OS... \"Windows\"\n",
    "        if \"xlsx\" in file:\n",
    "            excel_data.append(current_file_path)\n",
    "        elif \"csv\" in file:\n",
    "            csv_data.append(current_file_path)\n",
    "    break  # stop at first recursion level: only ./data\n",
    "\n",
    "print(f\"CSV:\\n{csv_data}\\nEXCEL:\\n{excel_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(filename: str):\n",
    "    data = pd.read_csv(filename, sep=\";\").replace(\",\", \".\", regex=True)\n",
    "\n",
    "    data.dropna(inplace=True)\n",
    "    data.drop(\n",
    "        index=data.index[0], axis=0, inplace=True\n",
    "    )  # instrument error causes first value to be nonsensical\n",
    "\n",
    "    for col in data.columns:\n",
    "        data[col] = data[col].apply(pd.to_numeric)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def read_excel(filename: str):\n",
    "    data = pd.read_excel(filename)\n",
    "    return data\n",
    "\n",
    "\n",
    "datasets = dict()\n",
    "\n",
    "for file in csv_data + excel_data:\n",
    "    key = os.path.basename(file).split(\".\")[0]\n",
    "    if \"csv\" in file:\n",
    "        datasets[key] = read_csv(file)\n",
    "    elif \"xlsx\" in file:\n",
    "        datasets[key] = read_excel(file)\n",
    "\n",
    "print(datasets.keys())\n",
    "\n",
    "for k in datasets.keys():\n",
    "    print(f\"\\nkey: {k}\")\n",
    "    datasets[k].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze data\n",
    "\n",
    "For the **static method**, the sonar's signal is hypothesized to have a very small amplitude, so the measure of the mass' displacement is the mean of the recorded positions.<BR><BR>\n",
    "For the **dynamic method**, we isolate the peaks of the oscillating signal and compute the mean of the period between two adjacent peaks. From there, the resulting period is used to approximate the frequency of the oscillation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_keys = list(filter(lambda k: \"statico\" in k, datasets.keys()))\n",
    "dynamic_keys = list(filter(lambda k: \"dinamico\" in k, datasets.keys()))\n",
    "\n",
    "print(f\"{static_keys}\\n{dynamic_keys}\")\n",
    "\n",
    "static_datasets = {k: datasets[k] for k in static_keys}\n",
    "dynamic_datasets = {k: datasets[k] for k in dynamic_keys}\n",
    "\n",
    "masses = datasets[\"misure_masse\"]  # it's going to be used a lot, so..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze static method\n",
    "\n",
    "averages = np.zeros(7)\n",
    "for run in range(7):\n",
    "    averages[run] += np.mean(data[f\"Run{run+1}(mm)\"])\n",
    "\n",
    "averages = np.round_(averages, decimals=2)\n",
    "print(averages)\n",
    "\n",
    "# k = 9.81 * (masse[-1] - masse[0]) / (averages[-1] - averages[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze dynamic method\n",
    "\n",
    "\n",
    "def discrete_derivative(domain: list, curve: list):\n",
    "    d = [0]\n",
    "    for i in range(1, len(curve)):\n",
    "        d.append((curve[i] - curve[i - 1]) / (domain[i] - domain[i - 1]))\n",
    "    return d\n",
    "\n",
    "\n",
    "# windowed peaks isolation\n",
    "def windowed_peaks(signal: list):\n",
    "    peaks = []\n",
    "    for i in range(2, len(signal) - 2, 4):\n",
    "        if (\n",
    "            reduce(\n",
    "                lambda x, y: x * y,\n",
    "                discrete_derivative(list(range(i - 2, i + 3)), signal[i - 2 : i + 3]),\n",
    "            )\n",
    "            < 0\n",
    "        ):\n",
    "            peaks.append(max(signal[i - 2 : i + 3]))\n",
    "    return peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_period(column_id: str):\n",
    "    wf = data[column_id].array\n",
    "    for v in wf:\n",
    "        print(windowed_peaks(wf))\n",
    "\n",
    "\n",
    "# calculate_mean_period(data[data.columns[0]])\n",
    "\n",
    "# for col in data.columns:\n",
    "# calculate_mean_period(col)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
